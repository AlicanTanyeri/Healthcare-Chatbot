{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from datasets import Dataset\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_file('YOUR-PATH-HERE')\n",
    "test_dataset = Dataset.from_file('YOUR-PATH-HERE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = train_dataset.select_columns([\"doctor_title\", \"doctor_speciality\", \"question_content\", \"question_answer\"])\n",
    "df_train = selected_columns.to_pandas()\n",
    "\n",
    "selected_columns = test_dataset.select_columns([\"doctor_title\", \"doctor_speciality\", \"question_content\", \"question_answer\"])\n",
    "df_test = selected_columns.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (150105, 4)\n",
      "Test shape: (37527, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training shape: {df_train.shape}\")\n",
    "print(f\"Test shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train.apply(\n",
    "    lambda row: f\"soru: {clean_text(row['question_content'])} cevap: {clean_text(row['question_answer'])}\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_test['text'] = df_test.apply(\n",
    "    lambda row: f\"soru: {clean_text(row['question_content'])} cevap: {clean_text(row['question_answer'])}\", \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['fasttext_line'] = df_train.apply(\n",
    "    lambda row: f\"__label__{row['doctor_speciality']} {row['text']}\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_test['fasttext_line'] = df_test.apply(\n",
    "    lambda row: f\"__label__{row['doctor_speciality']} {row['text']}\", \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'YOUR-PATH-HERE'\n",
    "test_file = 'YOUR-PATH-HERE'\n",
    "\n",
    "with open(train_file, 'w', encoding='utf-8') as f:\n",
    "    for line in df_train['fasttext_line']:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "with open(test_file, 'w', encoding='utf-8') as f:\n",
    "    for line in df_test['fasttext_line']:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 3M words\n",
      "Number of words:  207437\n",
      "Number of labels: 108\n",
      "Progress: 100.0% words/sec/thread:  212720 lr:  0.000000 avg.loss:  0.468381 ETA:   0h 0m 0s  2.6% words/sec/thread:  214347 lr:  0.292306 avg.loss:  3.336607 ETA:   0h 8m37s  4.7% words/sec/thread:  228833 lr:  0.285925 avg.loss:  2.902667 ETA:   0h 7m54s  5.7% words/sec/thread:  232806 lr:  0.282793 avg.loss:  2.729100 ETA:   0h 7m40s 11.8% words/sec/thread:  238800 lr:  0.264709 avg.loss:  2.068113 ETA:   0h 7m 0s 11.9% words/sec/thread:  238967 lr:  0.264368 avg.loss:  2.059685 ETA:   0h 6m59s 12.4% words/sec/thread:  238560 lr:  0.262855 avg.loss:  2.020846 ETA:   0h 6m58s 19.4% words/sec/thread:  233199 lr:  0.241776 avg.loss:  1.606492 ETA:   0h 6m33s 20.5% words/sec/thread:  232775 lr:  0.238442 avg.loss:  1.555373 ETA:   0h 6m28s% words/sec/thread:  226504 lr:  0.226749 avg.loss:  1.398087 ETA:   0h 6m19s 223939 lr:  0.218283 avg.loss:  1.301667 ETA:   0h 6m 9s 31.9% words/sec/thread:  217275 lr:  0.204350 avg.loss:  1.166781 ETA:   0h 5m56s words/sec/thread:  215750 lr:  0.198236 avg.loss:  1.117673 ETA:   0h 5m48s 39.8% words/sec/thread:  213541 lr:  0.180477 avg.loss:  0.992424 ETA:   0h 5m20s 43.3% words/sec/thread:  211883 lr:  0.170208 avg.loss:  0.930978 ETA:   0h 5m 4s 44.4% words/sec/thread:  210978 lr:  0.166746 avg.loss:  0.910928 ETA:   0h 4m59s 45.0% words/sec/thread:  210865 lr:  0.165036 avg.loss:  0.901836 ETA:   0h 4m56s 49.4% words/sec/thread:  211593 lr:  0.151948 avg.loss:  0.837256 ETA:   0h 4m32s 50.1% words/sec/thread:  211675 lr:  0.149767 avg.loss:  0.827444 ETA:   0h 4m28s 57.1% words/sec/thread:  210634 lr:  0.128800 avg.loss:  0.745650 ETA:   0h 3m52s 63.3% words/sec/thread:  212318 lr:  0.110114 avg.loss:  0.685099 ETA:   0h 3m16s 66.3% words/sec/thread:  212493 lr:  0.100961 avg.loss:  0.658837 ETA:   0h 3m 0s 0.100602 avg.loss:  0.657685 ETA:   0h 2m59s 67.1% words/sec/thread:  212034 lr:  0.098641 avg.loss:  0.652155 ETA:   0h 2m56s 72.8% words/sec/thread:  209730 lr:  0.081704 avg.loss:  0.609968 ETA:   0h 2m27s 74.4% words/sec/thread:  209636 lr:  0.076932 avg.loss:  0.599090 ETA:   0h 2m19s 75.4% words/sec/thread:  209786 lr:  0.073838 avg.loss:  0.592295 ETA:   0h 2m13s 76.3% words/sec/thread:  209114 lr:  0.071170 avg.loss:  0.586719 ETA:   0h 2m 9s 76.5% words/sec/thread:  209048 lr:  0.070525 avg.loss:  0.585371 ETA:   0h 2m 8s 78.3% words/sec/thread:  208290 lr:  0.065192 avg.loss:  0.574473 ETA:   0h 1m58s 81.3% words/sec/thread:  208304 lr:  0.056197 avg.loss:  0.556916 ETA:   0h 1m42s 82.2% words/sec/thread:  208367 lr:  0.053265 avg.loss:  0.551218 ETA:   0h 1m37s 90.3% words/sec/thread:  210353 lr:  0.028987 avg.loss:  0.509820 ETA:   0h 0m52s 90.6% words/sec/thread:  210393 lr:  0.028158 avg.loss:  0.508495 ETA:   0h 0m50s 94.4% words/sec/thread:  211337 lr:  0.016900 avg.loss:  0.491555 ETA:   0h 0m30s 96.4% words/sec/thread:  212022 lr:  0.010720 avg.loss:  0.482692 ETA:   0h 0m19s 96.7% words/sec/thread:  212038 lr:  0.009971 avg.loss:  0.481644 ETA:   0h 0m17s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "/home/alicantanyeri/Belgeler/doctor_speciality_classification/Distilbert-HealtcareAssistant/fasttext_healthcare.bin cannot be opened for saving!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      1\u001b[39m model = fasttext.train_supervised(\n\u001b[32m      2\u001b[39m     \u001b[38;5;28minput\u001b[39m=train_file,\n\u001b[32m      3\u001b[39m     lr=\u001b[32m0.3\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     thread=\u001b[32m4\u001b[39m\n\u001b[32m     12\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/home/alicantanyeri/Belgeler/doctor_speciality_classification/Distilbert-HealtcareAssistant/fasttext_healthcare.bin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/fasttext/FastText.py:311\u001b[39m, in \u001b[36m_FastText.save_model\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[32m    310\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Save the model to the given path\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43msaveModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: /home/alicantanyeri/Belgeler/doctor_speciality_classification/Distilbert-HealtcareAssistant/fasttext_healthcare.bin cannot be opened for saving!"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(\n",
    "    input=train_file,\n",
    "    lr=0.3,\n",
    "    epoch=128,\n",
    "    wordNgrams=2,\n",
    "    dim=100,\n",
    "    minn=2,\n",
    "    maxn=5,\n",
    "    loss='softmax',\n",
    "    verbose=2,\n",
    "    thread=4\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_path = 'YOUR-PATH-HERE'\n",
    "\n",
    "# Eğer klasör değilse ama aynı isimde dosya varsa\n",
    "if os.path.exists(save_path) and not os.path.isdir(save_path):\n",
    "    print(\"Aynı isimde dosya var, kaldırılıyor...\")\n",
    "    os.remove(save_path)  # veya taşı: shutil.move()\n",
    "    os.makedirs(save_path)  # klasörü oluştur\n",
    "elif not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# Artık model güvenle kaydedilebilir\n",
    "model.save_model(os.path.join(save_path, \"fasttext_healthcare.bin\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9886\n",
      "F1 Score: 0.9874\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Detailed evaluation\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    text = row['text']\n",
    "    true_label = row['doctor_speciality']\n",
    "    \n",
    "    predictions = model.predict(text, k=1)\n",
    "    pred_label = predictions[0][0].replace('__label__', '')\n",
    "    \n",
    "    y_true.append(true_label)\n",
    "    y_pred.append(pred_label)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
